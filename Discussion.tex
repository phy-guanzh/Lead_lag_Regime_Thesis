%% ----------------------------------------------------------------
%% Chapter — Discussion (revised: ≤3 sections, no summary)
%% ----------------------------------------------------------------
\chapter{Discussion}\label{Chapter:Discussion}

This chapter interprets the evidence rather than re-reporting it. We explain what the regime-aware overlay changes relative to the lead--lag hedge, why those changes plausibly work, and how robust and implementable they look. We then state the main limitations and sketch next steps. Conventions and headline metrics appear in Section \ref{sec:results:headline}; we refer to them without repeating details.

\section{Interpreting the findings}\label{sec:disc:interpret}

The overlay improves return per unit risk while \emph{holding participation constant} (Table~\ref{tab:main}). Therefore, the gain comes from selection and timing, not leverage. Figure~\ref{fig:nav} shows a smoother equity curve; Table~\ref{tab:diag_dd} shows a softer left tail and faster recovery. Figure~\ref{fig:roll_sharpe_6m} adds the dynamic view: the overlay spends more time above a 6-month Sharpe of 1 and shortens the negative pockets around 2022. In calendar time (Table~\ref{tab:eoy}), the overlay helps most when the baseline is misaligned or when regime shifts are sharp; when the baseline is already onside, marginal gains shrink.

Why does this happen? The baseline is a fixed long-followers/short-leaders hedge. The overlay routes that hedge through state labels linked to BTC path geometry. In favourable states it tilts toward assets that propagate the anchor; in adverse states it flips the sign while \emph{preserving} the hedge. Gross exposure stays similar, but composition rotates with the state. This reduces whipsaws and trims losses early when conditions turn.

\section{Sensitivity and implementability}\label{sec:disc:robust}

Across strict walk-forward runs, short windows with more paths dominate (Table~\ref{tab:top5_sharpe_params}). In particular, \(n_{\text{steps}}{=}5\) with \(n_{\text{paths}}\in\{16,20\}\) balances sensitivity and stability; mid-length settings improve on the baseline but with lower Sharpe. This pattern is consistent with a bias–variance trade-off: long windows blur turning points, while too few paths raise variance in the distance estimates.

Statistical checks support a cautious reading. Against zero, the top configuration is significant and its block-bootstrap confidence intervals exclude zero; the next is marginal. However, after White’s Reality Check (WRC) \cite{White2000} and Hansen’s SPA (SPA) \cite{Hansen2005}, we cannot reject no outperformance relative to the baseline (overall \(p\approx0.66\); see Table~\ref{tab:wrc_spa}). Hence we emphasise absolute improvement and drawdown control, not a guaranteed beat of the baseline.

Finally, implementability hinges on turnover. Costs erode performance roughly in proportion to annualised turnover. The baseline breaks even between 5–10 bps/side (Table~\ref{tab:baseline_tc}). The best overlay remains attractive at 5–10 bps because average turnover is lower, but performance compresses beyond 25 bps (Table~\ref{tab:tc_sensitivity_reduced}). Simple throttles help in practice: skip small basket changes, increase rebalance spacing in high-noise states, and cap participation relative to liquidity.

\section{Limitations and next steps}\label{sec:disc:limits}

Scope comes first. The sample is daily and limited to \sampleStart{}–\sampleEnd{} with a crypto-centric anchor; external validity to other regimes or asset classes is not guaranteed. Second, the single-anchor design risks omitted-state bias if leadership rotates outside BTC; multi-anchor or hierarchical states are a natural extension. Third, several hyperparameters are fixed (kernel scale, order, regularisation). Mis-scaling can over- or under-smooth geometry, and unbiased MMD raises variance in small training windows.

Label construction also matters. Voting over the last \(k\) groups reduces jitter but adds lag; close calls near turning points can flip. Lead--lag compression to a row-mean discards pairwise uncertainty and can over-reward near-ties in lag choice. Data handling imposes further constraints: winsorisation trims extremes; funding/borrow and market impact are simplified; reported headline metrics are gross of costs unless stated.

Finally, inference carries model-selection risk. Hyperparameters were chosen plausibly rather than via nested, walk-forward cross-validation. Multiple testing remains a threat despite our compact grid; WRC/SPA results underscore that caution. Next steps follow directly: extend to \emph{multi-anchor} regimes; add \emph{uncertainty-aware} scaling that gates gross exposure by state confidence; incorporate execution-aware controls (impact, latency, borrow/funding); and formalise selection with step-down SPA or a model-confidence set.
